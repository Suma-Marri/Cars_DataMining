---
title: "Car Pricing: Partitioning and Hierarchical Clustering"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---
-------------------------------------------------------------------------------

## Loading the Data
```{r}
Cars_df <- read.csv(
  file = "C:/Users/Suma Marri/Documents/GitHub/USCars/USA_cars_datasets.csv",
  )
Cars_df
```
This US Cars Dataset data was scraped from AUCTION EXPORT.com. 
The dataset includes information about 28 brands of clean and used vehicles for sale in US.

```{r}
price <- as.integer(Cars_df$price)
mileage <- as.double(Cars_df$mileage)
year <- as.factor(Cars_df$year)
d <- data.frame(year, mileage, price)
d
```

## Partitioning Unsupervised Learning
### K-Means Clustering

```{r}
#Scaling the data to remove influence caused by large variance
library(dplyr)
scaled_df <- d%>%mutate_if(is.numeric,scale)
scaled_df
```


```{r}
library(factoextra)
kmeans_scaled_df_2 <- kmeans(scaled_df[-1], centers = 2)
kmeans_scaled_df_3 <- kmeans(scaled_df[-1], centers = 3)
kmeans_scaled_df_4 <- kmeans(scaled_df[-1], centers = 4)
kmeans_scaled_df_5 <- kmeans(scaled_df[-1], centers = 5)
kmeans_scaled_df_6 <- kmeans(scaled_df[-1], centers = 6)
kmeans_scaled_df_7 <- kmeans(scaled_df[-1], centers = 7)

#Plots for comparison
p1 <- fviz_cluster(kmeans_scaled_df_2, geom = "point", data = scaled_df[-1]) + ggtitle("k = 2")
p2 <- fviz_cluster(kmeans_scaled_df_3, geom = "point",  data = scaled_df[-1]) + ggtitle("k = 3")
p3 <- fviz_cluster(kmeans_scaled_df_4, geom = "point",  data = scaled_df[-1]) + ggtitle("k = 4")
p4 <- fviz_cluster(kmeans_scaled_df_5, geom = "point",  data = scaled_df[-1]) + ggtitle("k = 5")
p5 <- fviz_cluster(kmeans_scaled_df_6, geom = "point",  data = scaled_df[-1]) + ggtitle("k = 6")
p6 <- fviz_cluster(kmeans_scaled_df_7, geom = "point",  data = scaled_df[-1]) + ggtitle("k = 7")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 2)
```

```{r}
set.seed(1)
factoextra::fviz_nbclust(
  x = scaled_df[-1],
  FUNcluster = kmeans,
  method = "wss")
```

```{r}
set.seed(1)
factoextra::fviz_nbclust(
  x = scaled_df[-1],
  FUNcluster = kmeans,
  method = "silhouette")
```

```{r}
set.seed(1)
clusGap_kmeans <- cluster::clusGap(
  x = scaled_df[-1],  
  FUNcluster = kmeans,  
  K.max = 12)
fviz_gap_stat(clusGap_kmeans)
```
```{r}
set.seed(1)
factoextra::fviz_nbclust(  
  x = scaled_df[-1],  
  FUNcluster = kmeans,  
  method = "gap_stat")
```

#### K-means clustering
For the final analysis we can compare the results/centers for k=2, k=3, and k=7.

```{r}
kmeans_scaled_df_2
fviz_cluster(kmeans_scaled_df_2, geom = "point", data = scaled_df[-1]) + ggtitle("k = 2")
kmeans_scaled_df_3
fviz_cluster(kmeans_scaled_df_3, geom = "point", data = scaled_df[-1]) + ggtitle("k = 3")
kmeans_scaled_df_7
fviz_cluster(kmeans_scaled_df_7, geom = "point", data = scaled_df[-1]) + ggtitle("k = 7")
```


### Cluster package in R

#### cluster::clara()
```{r}
clara_d <- cluster::clara(
  x = scaled_df[-1],
  k = 2
)
plot(clara_d)
print(clara_d)
```
#### cluster::fanny()
```{r}
fanny_d <- cluster::fanny(
  x = scaled_df[-1],
  k = 2
)
plot(fanny_d)
print(fanny_d)
```
#### cluster::pam()
```{r}
pam_d <- cluster::pam(scaled_df[-1],
                      k=2)
plot(pam_d)
print(pam_d)
```
## Hierarchical Clustering
### hclust()
```{r}
#Creating a distance matrix for the scaled dataset used in the analysis
dist_d <- dist(
  x=scaled_df[-1],
  method = 'euclidean'
)

#Performing hierarchical clustering
hclust_d <- hclust(
  d = dist_d,
  method = 'average'
)

plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2, col = 'red')

#coefficient for clustering
coef(hclust_d)
```

```{r}
set.seed(1)
#Reducing the size of the randomly to visualize the dendogram
reduced_scaled_df <- scaled_df[sample(nrow(scaled_df), 200), ]
reduced_scaled_df

#Creating a distance matrix for the scaled dataset used in the analysis using euclidean distance
dist_d <- dist(
  x=reduced_scaled_df[-1],
  method = 'euclidian'
)
```

```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'average'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```

```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```

```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'ward.D'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```
```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```

```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'ward.D2'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```
```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```
```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'complete'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```

```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```

```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'mcquitty'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```

```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```

#### Performing hierarchical clustering
```{r}
hclust_d <- hclust(
  d = dist_d,
  method = 'single'
)
plot(hclust_d)
rect.hclust(hclust_d , k = 2, border = 2:6)
abline(h = 2.5, col = 'red')
#coefficient for clustering
coef(hclust_d)
```

```{r}
cutree_d <- cutree(
  tree = hclust_d,
  k = 2
)

silhouette_d <- cluster::silhouette(
  x = cutree_d,
  dist = dist_d
)
plot(
  x = silhouette_d
)
```

### cluster::agnes()

```{r}
agnes_d <- cluster::agnes(reduced_scaled_df[-1])
plot(agnes_d)
#coefficient for clustering
coef(agnes_d)
```
### cluster::diana()
```{r}
diana_d <- cluster::diana(reduced_scaled_df[-1])
plot(diana_d)
#coefficient for clustering
coef(diana_d)
```
### cluster::mona()
```{r}
binary_d <- reduced_scaled_df[-1]
for(j in 1:ncol(binary_d)) binary_d[,j] <- as.numeric(
  binary_d[,j] > median(binary_d[,j])
)
mona_d <- cluster::mona(binary_d)
plot(mona_d)
```

